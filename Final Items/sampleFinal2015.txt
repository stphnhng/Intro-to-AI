sample final exam.

CSE 415, Spring 2015



The actual final will be formatted differently, and might have more
or fewer questions than this.  However, these sample questions will
likely be useful in studying for the exam.




1. (20 points)
 Give a definition for a Python class URN that can be called with
a construction call such as 
marble_jar = URN({'red': 3, 'blue': 1})

and having a method DRAW() that randomly selects an item from the urn
and returns it.  This method selects without replacement.  For example,
the following code might have the output shown:

try:
  for i in range(10):
    print(marble_jar.DRAW())
except URN_EMPTY as e:
  print("No more items in urn.")

red
blue
red
red
No more items in urn.

Your __init__ method should therefore accept a dictionary of (string, integer)
pairs, and any instance of URN should keep track of how many of each type
of item is left.  You may use the random.choice method of the random module
if you wish.  The probability of any particular kind of item should be equal
to the fraction the items left that are of that particular type.
For example, in the first call to DRAW above, the probability of getting
'blue' should be 1/4, but in the second call, the probability should be 1/3.
The probability of getting 'blue' in the third call should be 0, since there
are no 'blue' items left in the urn.


2. (20 points)

Write a Python function definition that returns the heuristic value associated
with the 15 puzzle, based on the Manhattan distance. Assume here that the blank
square is represented by 0, and that its distance from its position in the 
current state to its position in the goal should be included in the sum.


sample_start = [[ 2,  7, 12,  1],\
                [ 0,  5, 10, 15],\
                [ 4,  9, 14,  1],\
                [ 6, 11,  3,  8]]

goal = [[ 0,  1,  2,  3],\
        [ 4,  5,  6,  7],\
        [ 8,  9, 10, 11],\
        [12, 13, 14, 15]]

def h_manhattan(n):



3. (20 points)
Consider the following sequence of "facts" that are being entered into an ISA hierarchy
as part of a knowledge base.
 An A is a B.
 An A is a C.
 An X is a Y.
 A Z is a C.
 A Y is an A.
 A Z is an X.

a. (5 points) Identify the redundant fact.

b.    (15 points)

Assume that facts such as these are represented by the edges of a directed
graph.  For example, the fact "An X is a Y" is represented by an edge from
a vertex associated with X to a vertex associated with Y.
Give an algorithm that can find, for any new edge (v1, v2), facts
made redundant, based on transitivity, by the addition of edge (v1, v2).

Use English or pseudocode to describe the algorithm.   You may assume the
existence of a set of VERTICES, a set of EDGES, and a function ISA_TEST(x, y)
that returns True if an x is a y, via any given fact or valid path.


4. (20 points).
 Consider the wicked problem of providing enough food for the expected world
population in the year 2050.  There are many ways that someone could think about
trying to solve this problem, including such things as developing micro gardens
that people could have in their houses, like fish aquariums, 3D printers that
print food from ingredients like wheat flour and corn syrup, genetic engineering
of protein producers, etc.  Illustrate the state-space search method of structuring
a problem by making up possible (or at least conceivable) entries for each of the
components below.  (If you prefer, select another wicked problem, such as
stopping global warming, controlling the spread of drug-resistant diseases,
or reversing the tide of weapons proliferation in rogue states.)


 a. initial state (5 points). Suggest at least two state variables and explain
the units or ranges of values that they could take on.

 b. at least two operators (10 points) including their preconditions and state-transformation
functions.  These could represent actions that a company or that a government might take
to help solve the problem.

 c. a goal criterion (5 points) consisting of a predicate that could be applied to
a state to determine whether or not a path has been found through the state space
that represents a solution plan.


5. (20 points)
 Bayes Rule tells us how to get posterior probabilities from priors, likelihoods and evidence:
 P(H | E) =  P(E | H) P(H) / P(E).

 When the evidence consists of a sequence of features e_0, e_1, ..., e_{n-1},
  the joint probability distribution of these features and H can be an intractibly large table.
  For example, if each e_i has two possible values and H can have two possible values, the
  table would be of size 2^{n+1}.

 a. (10 points).
 As a practical matter, it is common to assume that this joint probability distribution can
 be factored, as if the e_i given H were conditionally independent.  Complete the formula
 that gives this approximation:

 P(E | H ) = P( e_0 and e_1 and ... and e_{n-1} | H ) ~ 


 b. (10 points). 
 What will happen to a classifier using the model above if the estimate of 
 likelihood P(e_i | H) is set to 0 due to bad luck with sampling the distribution?

 Suggest a way to fix this without doing any more sampling.


6. (20 points). Consider the following joint probability distribution.

 e_0 = L = light rain
 e_1 = W = warm temperature
 G = good fishing 

 L  W  G   P(L,M,G)
---------------
 T  T  T   0.2
 T  T  F   0.05
 T  F  T   0.05
 T  F  F   0.1
 F  T  T   0.05
 F  T  F   0.2
 F  F  T   O.05
 F  F  F   O.3

a. (5 points).
Compute the following marginal probabilities:
P(L)
P(W)
P(G)

b. (5 points)
Compute the following likelihoods:
P(L | G)
P(L | ~G)
P(W | G)
P(W | ~G)
P(~L | G)

c. (5 points)
Use Bayes' Rule to compute P(G | ~L ^ W), which is the probability of
good fishing given the conditions that there's no light rain but the
temperator is warm.

d. (5 points)
Use the Naive Bayes technique to estimate P(G | ~L ^ W).


7. (20 points)

Consider the following semantic grammar for a robot control interface.


<command> ->  <operation> the <object> 
<command> ->  <command> and then <command>
<command> ->  help on <operation>
<operation> -> store | wash | tidy up | get me
<object> -> dinner plates | table | wine glasses | silverware

Draw a parse tree for the following command:

tidy up the table and then get me the wine glasses

8. (20 points).

Suppose we are going to apply the Hough transform to identify those
light (not dark)
horizontal and vertical lines that have the greatest evidence of
occurrence in a binary image.   The binary image uses pixel value
0 to represent black and pixel value 1 to represent white.

Here is the binary image


1  0  0  1  0

0  0  0  0  0

1  1  0  1  1

0  1  0  1  0

0  1  0  0  0

a. (10 points)
Fill in the values of the array that represents H(theta, rho).

                         rho
               -2   -1    0    1    2

theta:  0

        pi/2


b. (5 points)
Circle the largest element of this array.

c. (5 points)
Draw a line on the binary image that corresponds to this largest element.


9. (20 points)

a. (15 points)
 State the three laws of robots, according to Isaac Asimov.

   (5 points)
b. Explain one of the difficulties of achieving the design and deployment of
robots that adhere to these laws.



10. (20 points).
According to Ray Kurzweil, something remarkable can be expected to happen in the
future, possibly around the year 2041. 

a. (5 points)
What is the name he gives to this predicted phenomenon?

b. (10 points)
Describe the basic idea of the phenomenon.

c. (5 points)
To what extent do you agree with this prediction, and why?





